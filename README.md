# Tracking Everything Everywhere All at Once


[Qianqian Wang](https://www.cs.cornell.edu/~qqw/)<sup>1,2</sup>, 
[Yen-Yu Chang](https://yuyuchang.github.io/)<sup>1</sup>, 
[Ruojin Cai](https://www.cs.cornell.edu/~ruojin/)<sup>1</sup>, 
[Zhengqi Li](https://zhengqili.github.io/)<sup>2</sup>, 
[Bharath Hariharan](https://www.cs.cornell.edu/~bharathh/)<sup>1</sup>,
[Aleksander Holynski](https://holynski.org/)<sup>2,3</sup>, 
[Noah Snavely](https://www.cs.cornell.edu/~snavely/)<sup>1,2</sup>
<br>
<sup>1</sup>Cornell University,  <sup>2</sup>Google Research,  <sup>3</sup>UC Berkeley  

#### [Project Page](https://omnimotion.github.io/) | [Paper](https://arxiv.org/pdf/2306.05422.pdf) | [Video](https://www.youtube.com/watch?v=KHoAG3gA024)

Implementation for paper "Tracking Everything Everywhere All at Once", which proposes a new method to jointly track all points in a video across all frames, even through occlusions.

This is not an officially supported Google product.

## Citation

```
@article{wang2023omnimotion,
  title   = {Tracking Everything Everywhere All at Once},
  author  = {Wang, Qianqian and Chang, Yen-Yu and Cai, Ruojin and Li, Zhengqi and Hariharan, Bharath and Holynski, Aleksander and Snavely, Noah},
  journal = {arXiv:2306.05422},
  year    = {2023}
}
```
